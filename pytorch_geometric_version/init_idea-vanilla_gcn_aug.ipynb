{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6qvp048fi06",
        "outputId": "707b3ab0-a64b-40be-b5e8-eb2a07876a10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ[\"TORCH\"] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoWDa5gHfiyP",
        "outputId": "c94f6636-55a9-4138-c2a6-563b6bbf1b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 2.8 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFAPi6rSKFC6",
        "outputId": "bc443f5d-7f2f-4dfc-f864-b9644c8f18e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Nov  3 15:37:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgIpZJnZfqy0"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import copy\n",
        "import argparse\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj\n",
        "from torch_geometric.utils import structured_negative_sampling, subgraph, k_hop_subgraph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rL-7y7SS64lb"
      },
      "outputs": [],
      "source": [
        "data_path = \"pytorch_geometric_version/data/\"\n",
        "# data_path = '/content/drive/MyDrive/AI_Naver_PTIT/KGCN/torch/data/'\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"\n",
        "    Data Loader class which makes dataset for training / knowledge graph dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.cfg = {\n",
        "            \"movie\": {\n",
        "                \"item2id_path\": data_path + \"movie/item_index2entity_id.txt\",\n",
        "                \"kg_path\": data_path + \"movie/kg.txt\",\n",
        "                \"rating_path\": data_path + \"movie/ratings.csv\",\n",
        "                \"rating_sep\": \",\",\n",
        "                \"threshold\": 4.0,\n",
        "            },\n",
        "            \"music\": {\n",
        "                \"item2id_path\": data_path + \"music/item_index2entity_id.txt\",\n",
        "                \"kg_path\": data_path + \"music/kg.txt\",\n",
        "                \"rating_path\": data_path + \"music/user_artists.dat\",\n",
        "                \"rating_sep\": \"\\t\",\n",
        "                \"threshold\": 0.0,\n",
        "            },\n",
        "            'kkbox': {\n",
        "                'item2id_path': data_path + \"KKBOX_data/item_index2entity_id.txt\",\n",
        "                'kg_path': data_path + \"KKBOX_data/kg.txt\",\n",
        "                'rating_path': data_path + \"KKBOX_data/user_item.dat\",\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 0.0\n",
        "            },\n",
        "            'ml100k': {\n",
        "                'item2id_path': data_path + \"ML100K/item_index2entity_id.txt\",\n",
        "                'kg_path': data_path + \"ML100K/kg.txt\",\n",
        "                'rating_path': data_path + \"ML100K/user_item.dat\",\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 0.0\n",
        "            }\n",
        "        }\n",
        "        self.data = data\n",
        "\n",
        "        df_item2id = pd.read_csv(\n",
        "            self.cfg[data][\"item2id_path\"], sep=\"\\t\", header=None, names=[\"item\", \"id\"]\n",
        "        )\n",
        "        df_kg = pd.read_csv(\n",
        "            self.cfg[data][\"kg_path\"],\n",
        "            sep=\"\\t\",\n",
        "            header=None,\n",
        "            names=[\"head\", \"relation\", \"tail\"],\n",
        "        )\n",
        "        df_rating = pd.read_csv(\n",
        "            self.cfg[data][\"rating_path\"],\n",
        "            sep=self.cfg[data][\"rating_sep\"],\n",
        "            names=[\"userID\", \"itemID\", \"rating\"],\n",
        "            skiprows=1,\n",
        "        )\n",
        "\n",
        "        # df_rating['itemID'] and df_item2id['item'] both represents old entity ID\n",
        "        df_rating = df_rating[df_rating[\"itemID\"].isin(df_item2id[\"item\"])]\n",
        "        df_rating.reset_index(inplace=True, drop=True)\n",
        "\n",
        "        self.df_item2id = df_item2id\n",
        "        self.df_kg = df_kg\n",
        "        self.df_rating = df_rating\n",
        "\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.entity_encoder = LabelEncoder()\n",
        "        self.relation_encoder = LabelEncoder()\n",
        "\n",
        "        self._encoding()\n",
        "\n",
        "    def _encoding(self):\n",
        "        \"\"\"\n",
        "        Fit each label encoder and encode knowledge graph\n",
        "        \"\"\"\n",
        "        self.user_encoder.fit(self.df_rating[\"userID\"])\n",
        "        # df_item2id['id'] and df_kg[['head', 'tail']] represents new entity ID\n",
        "        self.entity_encoder.fit(\n",
        "            pd.concat([self.df_item2id[\"id\"], self.df_kg[\"head\"], self.df_kg[\"tail\"]])\n",
        "        )\n",
        "        self.relation_encoder.fit(self.df_kg[\"relation\"])\n",
        "\n",
        "        # encode df_kg\n",
        "        self.df_kg[\"head\"] = self.entity_encoder.transform(self.df_kg[\"head\"])\n",
        "        self.df_kg[\"tail\"] = self.entity_encoder.transform(self.df_kg[\"tail\"])\n",
        "        self.df_kg[\"relation\"] = self.relation_encoder.transform(self.df_kg[\"relation\"])\n",
        "\n",
        "    def _build_dataset(self):\n",
        "        \"\"\"\n",
        "        Build dataset for training (rating data)\n",
        "        It contains negative sampling process\n",
        "        \"\"\"\n",
        "        print(\"Build dataset dataframe ...\", end=\" \")\n",
        "        # df_rating update\n",
        "        df_dataset = pd.DataFrame()\n",
        "        df_dataset[\"userID\"] = self.user_encoder.transform(self.df_rating[\"userID\"])\n",
        "\n",
        "        # update to new id\n",
        "        item2id_dict = dict(zip(self.df_item2id[\"item\"], self.df_item2id[\"id\"]))\n",
        "        self.df_rating[\"itemID\"] = self.df_rating[\"itemID\"].apply(\n",
        "            lambda x: item2id_dict[x]\n",
        "        )\n",
        "        df_dataset[\"itemID\"] = self.entity_encoder.transform(self.df_rating[\"itemID\"])\n",
        "        df_dataset[\"label\"] = self.df_rating[\"rating\"].apply(\n",
        "            lambda x: 0 if x < self.cfg[self.data][\"threshold\"] else 1\n",
        "        )\n",
        "\n",
        "        # negative sampling\n",
        "        df_dataset = df_dataset[df_dataset[\"label\"] == 1]\n",
        "        # df_dataset requires columns to have new entity ID\n",
        "        full_item_set = set(range(len(self.entity_encoder.classes_)))\n",
        "        user_list = []\n",
        "        item_list = []\n",
        "        label_list = []\n",
        "        for user, group in df_dataset.groupby([\"userID\"]):\n",
        "            item_set = set(group[\"itemID\"])\n",
        "            negative_set = full_item_set - item_set\n",
        "            negative_sampled = random.sample(negative_set, len(item_set))\n",
        "            user_list.extend([user] * len(negative_sampled))\n",
        "            item_list.extend(negative_sampled)\n",
        "            label_list.extend([0] * len(negative_sampled))\n",
        "        negative = pd.DataFrame(\n",
        "            {\"userID\": user_list, \"itemID\": item_list, \"label\": label_list}\n",
        "        )\n",
        "        df_dataset = pd.concat([df_dataset, negative])\n",
        "\n",
        "        df_dataset = df_dataset.sample(frac=1, replace=False, random_state=999)\n",
        "        df_dataset.reset_index(inplace=True, drop=True)\n",
        "        print(\"Done\")\n",
        "        return df_dataset\n",
        "\n",
        "    def _construct_kg(self):\n",
        "        \"\"\"\n",
        "        Construct knowledge graph\n",
        "        Knowledge graph is dictionary form\n",
        "        'head': [(relation, tail), ...]\n",
        "        \"\"\"\n",
        "        print(\"Construct knowledge graph ...\", end=\" \")\n",
        "        kg = dict()\n",
        "        for i in range(len(self.df_kg)):\n",
        "            head = self.df_kg.iloc[i][\"head\"]\n",
        "            relation = self.df_kg.iloc[i][\"relation\"]\n",
        "            tail = self.df_kg.iloc[i][\"tail\"]\n",
        "            if head in kg:\n",
        "                kg[head].append((relation, tail))\n",
        "            else:\n",
        "                kg[head] = [(relation, tail)]\n",
        "            if tail in kg:\n",
        "                kg[tail].append((relation, head))\n",
        "            else:\n",
        "                kg[tail] = [(relation, head)]\n",
        "        print(\"Done\")\n",
        "        return kg\n",
        "\n",
        "    def load_dataset(self):\n",
        "        return self._build_dataset()\n",
        "\n",
        "    def load_kg(self):\n",
        "        return self._construct_kg()\n",
        "\n",
        "    def get_encoders(self):\n",
        "        return (self.user_encoder, self.entity_encoder, self.relation_encoder)\n",
        "\n",
        "    def get_num(self):\n",
        "        return (\n",
        "            len(self.user_encoder.classes_),\n",
        "            len(self.entity_encoder.classes_),\n",
        "            len(self.relation_encoder.classes_),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOc-sAwa64lc"
      },
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='music', help='which dataset to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=25, help='the number of epochs')\n",
        "# parser.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--batch_size', type=int, default=32, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW9lrmJVAzqu"
      },
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument(\"--dataset\", type=str, default=\"movie\", help=\"which dataset to use\")\n",
        "# parser.add_argument(\"--n_epochs\", type=int, default=1, help=\"the number of epochs\")\n",
        "# parser.add_argument(\n",
        "#     \"--dim\", type=int, default=32, help=\"dimension of user and entity embeddings\"\n",
        "# )\n",
        "# parser.add_argument(\"--batch_size\", type=int, default=65536, help=\"batch size\")\n",
        "# parser.add_argument(\n",
        "#     \"--l2_weight\", type=float, default=1e-7, help=\"weight of l2 regularization\"\n",
        "# )\n",
        "# parser.add_argument(\"--lr\", type=float, default=2e-2, help=\"learning rate\")\n",
        "# parser.add_argument(\"--ratio\", type=float, default=0.6, help=\"size of training dataset\")\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='kkbox', help='which dataset to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=5, help='the number of epochs')\n",
        "# parser.add_argument('--dim', type=int, default=32, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--batch_size', type=int, default=32768, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-7, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=2e-2, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='ml100k', help='which dataset to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=5, help='the number of epochs')\n",
        "# parser.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--batch_size', type=int, default=16, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "gDu2qqog64ld",
        "outputId": "36b2f051-04e2-4d45-ba3f-c5893ffadca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Construct knowledge graph ... Done\n",
            "Build dataset dataframe ... Done\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-da2b9ae0-15d0-4cf3-9acd-da2c3bd8a3e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>602</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>314</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8404</td>\n",
              "      <td>34655</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>462</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12826</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14947307</th>\n",
              "      <td>7348</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14947308</th>\n",
              "      <td>721</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14947309</th>\n",
              "      <td>90</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14947310</th>\n",
              "      <td>249</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14947311</th>\n",
              "      <td>580</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14947312 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da2b9ae0-15d0-4cf3-9acd-da2c3bd8a3e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-da2b9ae0-15d0-4cf3-9acd-da2c3bd8a3e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-da2b9ae0-15d0-4cf3-9acd-da2c3bd8a3e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "          userID  itemID  label\n",
              "0            602       3      1\n",
              "1            314       2      1\n",
              "2           8404   34655      0\n",
              "3            462       3      1\n",
              "4          12826       2      1\n",
              "...          ...     ...    ...\n",
              "14947307    7348       4      1\n",
              "14947308     721       0      1\n",
              "14947309      90       2      1\n",
              "14947310     249       2      1\n",
              "14947311     580       2      1\n",
              "\n",
              "[14947312 rows x 3 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build dataset and knowledge graph\n",
        "data_loader = DataLoader(args.dataset)\n",
        "kg = data_loader.load_kg()\n",
        "df_dataset = data_loader.load_dataset()\n",
        "df_dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfQI1bJT64ld"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class KGCNDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id = np.array(self.df.iloc[idx][\"userID\"])\n",
        "        item_id = np.array(self.df.iloc[idx][\"itemID\"])\n",
        "        label = np.array(self.df.iloc[idx][\"label\"], dtype=np.float32)\n",
        "        return user_id, item_id, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgV6Yq2i64ld"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df_dataset,\n",
        "    df_dataset[\"label\"],\n",
        "    test_size=1 - args.ratio,\n",
        "    shuffle=False,\n",
        "    random_state=999,\n",
        ")\n",
        "x_test, _, y_test, _ = train_test_split(\n",
        "    x_test, y_test, test_size=0.5, shuffle=False, random_state=999\n",
        ")\n",
        "train_dataset = KGCNDataset(x_train)\n",
        "test_dataset = KGCNDataset(x_test)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaJEag7gAs6d"
      },
      "source": [
        "### model v1 use learning weight of gcn to reduce the dimension at forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaAF5WvFAs6d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch.nn import Linear, Parameter\n",
        "\n",
        "\n",
        "class vanilla_gcn_aug_v1(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(vanilla_gcn_aug_v1, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.batch_size = args.batch_size\n",
        "        # self.max_neighbor = 600\n",
        "        self.max_neighbor = 20\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self._gen_adj()\n",
        "        # entity augment\n",
        "        self.dim_aug = self.num_ent + self.num_rel\n",
        "        self.ent_aug = torch.nn.Embedding.from_pretrained(\n",
        "            torch.tensor(self.list_ent_aug).type(torch.FloatTensor), freeze=True\n",
        "        )\n",
        "        # entity hidden\n",
        "        self.dim_hid = args.dim\n",
        "        self.ent_hid = torch.nn.Embedding(num_ent, self.dim_hid)\n",
        "        # user emb\n",
        "        self.usr = torch.nn.Embedding(num_user, self.dim_hid)\n",
        "        # linear transform\n",
        "        self.lin = Linear(self.dim_hid + self.dim_aug, self.dim_hid, bias=False)\n",
        "        self.bias = Parameter(torch.Tensor(self.dim_hid))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "\n",
        "        self.list_id_neighbor = np.full((self.num_ent, self.max_neighbor), -1)\n",
        "        self.list_ent_aug = np.full((self.num_ent, self.num_ent + self.num_rel), -1)\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.max_neighbor:\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.max_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors_to_sparse_coo_tensor = random.choices(\n",
        "                    self.kg[e], k=self.max_neighbor\n",
        "                )\n",
        "            self.list_id_neighbor[e] = [\n",
        "                ent for _, ent in neighbors_to_sparse_coo_tensor\n",
        "            ]\n",
        "\n",
        "            # get all neighbors\n",
        "            id_neighbor = [ent for _, ent in self.kg[e]]\n",
        "            id_neighbor.append(e)\n",
        "            id_edge = [rel for rel, _ in self.kg[e]]\n",
        "\n",
        "            # count\n",
        "            id_neighbor_count = np.bincount(id_neighbor)\n",
        "            id_neighbor_count = np.pad(\n",
        "                id_neighbor_count,\n",
        "                (0, self.num_ent - len(id_neighbor_count)),\n",
        "                \"constant\",\n",
        "                constant_values=(0),\n",
        "            )\n",
        "            id_edge_count = np.bincount(id_edge)\n",
        "            id_edge_count = np.pad(\n",
        "                id_edge_count,\n",
        "                (0, self.num_rel - len(id_edge_count)),\n",
        "                \"constant\",\n",
        "                constant_values=(0),\n",
        "            )\n",
        "\n",
        "            # concat\n",
        "            self.list_ent_aug[e] = np.concatenate((id_neighbor_count, id_edge_count))\n",
        "\n",
        "    def forward(self, user_indices, item_indices, device):\n",
        "\n",
        "        # src = np.concatenate((self.list_id_neighbor[item_indices].flatten(), item_indices))\n",
        "        # target = np.concatenate((np.array(np.repeat(item_indices, self.n_neighbor)), item_indices))\n",
        "\n",
        "        src = np.concatenate(\n",
        "            (self.list_id_neighbor[item_indices.cpu()].flatten(), item_indices.cpu())\n",
        "        )\n",
        "        target = np.concatenate(\n",
        "            (\n",
        "                np.array(np.repeat(item_indices.cpu(), self.max_neighbor)),\n",
        "                item_indices.cpu(),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        list_node_id_1_hop_item = np.unique(np.array([src, target]).T, axis=0)\n",
        "        list_node_id_1_hop_item = list_node_id_1_hop_item.T\n",
        "        list_node_id_1_hop_item = torch.tensor(list_node_id_1_hop_item).to(device)\n",
        "\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index = list_node_id_1_hop_item\n",
        "        # edge_index = list_node_id_1_hop_item\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "        x = torch.cat((self.ent_hid.weight, self.ent_aug.weight), 1)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Step 3: Compute normalization.\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float(\"inf\")] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Step 4-5: Start propagating messages.\n",
        "        item_embs_all = self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "        # Step 6: Apply a final bias vector.\n",
        "        item_embs_all += self.bias\n",
        "\n",
        "        user_embeddings = self.usr(user_indices)\n",
        "\n",
        "        item_embs = item_embs_all[item_indices]\n",
        "\n",
        "        scores = (item_embs * user_embeddings).sum(dim=-1)\n",
        "\n",
        "        return torch.sigmoid(scores)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        # Step 4: Normalize node features.\n",
        "        return norm.view(-1, 1) * x_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS_vIFmTfhoR"
      },
      "source": [
        "### model v2 use random projection to reduce the dimension at forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuCxMiQOfhoR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch.nn import Linear, Parameter\n",
        "from sklearn.random_projection import GaussianRandomProjection\n",
        "\n",
        "\n",
        "class vanilla_gcn_aug_v2(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(vanilla_gcn_aug_v2, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.batch_size = args.batch_size\n",
        "        # self.max_neighbor = 600\n",
        "        self.max_neighbor = 20\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self._gen_adj()\n",
        "\n",
        "        # entity augment\n",
        "        self.dim_aug = self.num_ent + self.num_rel\n",
        "        self.ent_aug = torch.nn.Embedding.from_pretrained(\n",
        "            torch.tensor(self.list_ent_aug).type(torch.FloatTensor), freeze=True\n",
        "        )\n",
        "\n",
        "        # entity hidden\n",
        "        self.dim_hid = args.dim\n",
        "        self.ent_hid = torch.nn.Embedding(num_ent, self.dim_hid)\n",
        "\n",
        "        # user emb\n",
        "        self.usr = torch.nn.Embedding(num_user, self.dim_hid)\n",
        "\n",
        "        # random projection\n",
        "        random_projector = GaussianRandomProjection(n_components=\"auto\", eps=0.2)\n",
        "        random_projector.fit(\n",
        "            np.full((self.num_ent, self.dim_hid + self.dim_aug), 0)\n",
        "        )  # simple create a matrix with shape like: torch.cat((self.ent_hid.weight, self.ent_aug.weight), 1)\n",
        "        num_output_random_projector = random_projector.components_.shape[\n",
        "            0\n",
        "        ]  # (numOutFeature, numOrginFeature)\n",
        "        self.random_projector = (\n",
        "            torch.tensor(np.linalg.pinv(random_projector.components_))\n",
        "            .type(torch.FloatTensor)\n",
        "            .to(device)\n",
        "        )  # get matrix random projection and transform to torch tensor\n",
        "\n",
        "        # linear transform\n",
        "        self.lin = Linear(num_output_random_projector, self.dim_hid, bias=False)\n",
        "        self.bias = Parameter(torch.Tensor(self.dim_hid))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "\n",
        "        self.list_id_neighbor = np.full((self.num_ent, self.max_neighbor), -1)\n",
        "        self.list_ent_aug = np.full((self.num_ent, self.num_ent + self.num_rel), -1)\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.max_neighbor:\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.max_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors_to_sparse_coo_tensor = random.choices(\n",
        "                    self.kg[e], k=self.max_neighbor\n",
        "                )\n",
        "            self.list_id_neighbor[e] = [\n",
        "                ent for _, ent in neighbors_to_sparse_coo_tensor\n",
        "            ]\n",
        "\n",
        "            # get all neighbors\n",
        "            id_neighbor = [ent for _, ent in self.kg[e]]\n",
        "            id_neighbor.append(e)\n",
        "            id_edge = [rel for rel, _ in self.kg[e]]\n",
        "\n",
        "            # count\n",
        "            id_neighbor_count = np.bincount(id_neighbor)\n",
        "            id_neighbor_count = np.pad(\n",
        "                id_neighbor_count,\n",
        "                (0, self.num_ent - len(id_neighbor_count)),\n",
        "                \"constant\",\n",
        "                constant_values=(0),\n",
        "            )\n",
        "            id_edge_count = np.bincount(id_edge)\n",
        "            id_edge_count = np.pad(\n",
        "                id_edge_count,\n",
        "                (0, self.num_rel - len(id_edge_count)),\n",
        "                \"constant\",\n",
        "                constant_values=(0),\n",
        "            )\n",
        "\n",
        "            # concat\n",
        "            self.list_ent_aug[e] = np.concatenate((id_neighbor_count, id_edge_count))\n",
        "\n",
        "    def forward(self, user_indices, item_indices, device):\n",
        "\n",
        "        src = np.concatenate(\n",
        "            (self.list_id_neighbor[item_indices.cpu()].flatten(), item_indices.cpu())\n",
        "        )\n",
        "        target = np.concatenate(\n",
        "            (\n",
        "                np.array(np.repeat(item_indices.cpu(), self.max_neighbor)),\n",
        "                item_indices.cpu(),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        list_node_id_1_hop_item = np.unique(np.array([src, target]).T, axis=0)\n",
        "        list_node_id_1_hop_item = list_node_id_1_hop_item.T\n",
        "        list_node_id_1_hop_item = torch.tensor(list_node_id_1_hop_item).to(device)\n",
        "\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index = list_node_id_1_hop_item\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "\n",
        "        # Gaussian Random Projection\n",
        "        x = torch.cat((self.ent_hid.weight, self.ent_aug.weight), 1)\n",
        "        x = torch.matmul(x, self.random_projector)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Step 3: Compute normalization.\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float(\"inf\")] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Step 4-5: Start propagating messages.\n",
        "        item_embs_all = self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "        # Step 6: Apply a final bias vector.\n",
        "        item_embs_all += self.bias\n",
        "\n",
        "        user_embeddings = self.usr(user_indices)\n",
        "\n",
        "        item_embs = item_embs_all[item_indices]\n",
        "\n",
        "        scores = (item_embs * user_embeddings).sum(dim=-1)\n",
        "\n",
        "        return torch.sigmoid(scores)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        # Step 4: Normalize node features.\n",
        "        return norm.view(-1, 1) * x_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abj9wTX-mU4v"
      },
      "source": [
        "### model v3 use random projection and learning weight to reduce the dimension at init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jkqD8kVmU4w"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "from torch_geometric.utils import add_self_loops, degree\n",
        "from torch.nn import Linear, Parameter\n",
        "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "class vanilla_gcn_aug_v3(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(vanilla_gcn_aug_v3, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.batch_size = args.batch_size\n",
        "        self.max_neighbor = 600\n",
        "        # self.max_neighbor = 20\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self._gen_adj()\n",
        "\n",
        "        # define random projection\n",
        "        # random_projector = GaussianRandomProjection(n_components='auto', eps=0.2)\n",
        "        random_projector = SparseRandomProjection(n_components=\"auto\", eps=0.2)\n",
        "\n",
        "        # entity augment\n",
        "        self.dim_aug = self.num_ent + self.num_rel\n",
        "        ent_aug = random_projector.fit_transform(self.list_ent_aug)\n",
        "        num_output_random_projector = random_projector.components_.shape[0]\n",
        "        print(num_output_random_projector)\n",
        "        print(random_projector.components_.shape)\n",
        "        self.ent_aug = torch.nn.Embedding.from_pretrained(\n",
        "            torch.tensor(ent_aug.toarray()).type(torch.FloatTensor), freeze=True\n",
        "        )\n",
        "\n",
        "        # entity hidden\n",
        "        self.dim_hid = args.dim\n",
        "        self.ent_hid = torch.nn.Embedding(num_ent, self.dim_hid)\n",
        "\n",
        "        # user emb\n",
        "        self.usr = torch.nn.Embedding(num_user, self.dim_hid)\n",
        "\n",
        "        # linear transform\n",
        "        self.lin = Linear(\n",
        "            num_output_random_projector + self.dim_hid, self.dim_hid, bias=False\n",
        "        )\n",
        "        self.bias = Parameter(torch.Tensor(self.dim_hid))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin.reset_parameters()\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "        self.list_id_neighbor = np.full((self.num_ent, self.max_neighbor), -1)\n",
        "        # self.list_ent_aug = np.full((self.num_ent, self.num_ent + self.num_rel), -1)\n",
        "        row = []\n",
        "        col = []\n",
        "        data = []\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.max_neighbor:\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.max_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors_to_sparse_coo_tensor = random.choices(\n",
        "                    self.kg[e], k=self.max_neighbor\n",
        "                )\n",
        "            self.list_id_neighbor[e] = [\n",
        "                ent for _, ent in neighbors_to_sparse_coo_tensor\n",
        "            ]\n",
        "\n",
        "            ent_list_tmp = []\n",
        "            rel_list_tmp = []\n",
        "            # print(\"kg[e]\")\n",
        "            # print(kg[e])\n",
        "            for rel, ent in self.kg[e]:\n",
        "                ent_list_tmp.append(ent)\n",
        "                rel_list_tmp.append(rel)\n",
        "\n",
        "            for ent in set(ent_list_tmp):\n",
        "                row.append(e)\n",
        "                col.append(ent)\n",
        "                data.append(ent_list_tmp.count(ent))\n",
        "            for rel in set(rel_list_tmp):\n",
        "                row.append(e)\n",
        "                col.append(self.num_ent + rel)\n",
        "                data.append(rel_list_tmp.count(rel))\n",
        "\n",
        "        self.list_ent_aug = csr_matrix(\n",
        "            (data, (row, col)), shape=(self.num_ent, self.num_ent + self.num_rel)\n",
        "        )\n",
        "\n",
        "    def forward(self, user_indices, item_indices, device):\n",
        "\n",
        "        src = np.concatenate(\n",
        "            (self.list_id_neighbor[item_indices.cpu()].flatten(), item_indices.cpu())\n",
        "        )\n",
        "        target = np.concatenate(\n",
        "            (\n",
        "                np.array(np.repeat(item_indices.cpu(), self.max_neighbor)),\n",
        "                item_indices.cpu(),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        list_node_id_1_hop_item = np.unique(np.array([src, target]).T, axis=0)\n",
        "        list_node_id_1_hop_item = list_node_id_1_hop_item.T\n",
        "        list_node_id_1_hop_item = torch.tensor(list_node_id_1_hop_item).to(device)\n",
        "\n",
        "        # Step 1: Add self-loops to the adjacency matrix.\n",
        "        edge_index = list_node_id_1_hop_item\n",
        "\n",
        "        # Step 2: Linearly transform node feature matrix.\n",
        "\n",
        "        # Gaussian Random Projection\n",
        "        x = torch.cat((self.ent_hid.weight, self.ent_aug.weight), 1)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        # Step 3: Compute normalization.\n",
        "        row, col = edge_index\n",
        "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
        "        deg_inv_sqrt = deg.pow(-0.5)\n",
        "        deg_inv_sqrt[deg_inv_sqrt == float(\"inf\")] = 0\n",
        "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
        "\n",
        "        # Step 4-5: Start propagating messages.\n",
        "        item_embs_all = self.propagate(edge_index, x=x, norm=norm)\n",
        "\n",
        "        # Step 6: Apply a final bias vector.\n",
        "        item_embs_all += self.bias\n",
        "\n",
        "        user_embeddings = self.usr(user_indices)\n",
        "\n",
        "        item_embs = item_embs_all[item_indices]\n",
        "\n",
        "        scores = (item_embs * user_embeddings).sum(dim=-1)\n",
        "\n",
        "        return torch.sigmoid(scores)\n",
        "\n",
        "    def message(self, x_j, norm):\n",
        "        # x_j has shape [E, out_channels]\n",
        "\n",
        "        # Step 4: Normalize node features.\n",
        "        return norm.view(-1, 1) * x_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47hw08Mix3c"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9azw7_BoGxmP",
        "outputId": "e0385fd8-2324-4f75-e92c-b90b05c56440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "2662\n",
            "(2662, 102601)\n",
            "device:  cuda\n"
          ]
        }
      ],
      "source": [
        "# prepare network, loss function, optimizer\n",
        "num_user, num_entity, num_relation = data_loader.get_num()\n",
        "user_encoder, entity_encoder, relation_encoder = data_loader.get_encoders()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = vanilla_gcn_aug_v3(num_user, num_entity, num_relation, kg, args, device).to(\n",
        "    device\n",
        ")\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2_weight)\n",
        "print(\"device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9VfJFwp64ld",
        "outputId": "396bd9b1-d4d6-42ac-ed96-c10f76248b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start_train: 1667490098.1362097\n",
            "[Epoch 1]\n",
            "train_loss:  0.0765174658081909\n",
            "test_loss:  0.004492022648818143\n",
            "test_auc:  0.9980083262318239\n",
            "test_f1:  0.9994990055350182\n",
            "--------------------------------\n",
            "end_train: 1667499220.9527242\n",
            "end_train - start_train: 9122.816514492035\n"
          ]
        }
      ],
      "source": [
        "loss_list = []\n",
        "test_loss_list = []\n",
        "auc_score_list = []\n",
        "f1_score_list = []\n",
        "\n",
        "import time\n",
        "\n",
        "start_train = time.time()\n",
        "print(\"start_train:\", start_train)\n",
        "\n",
        "for epoch in range(args.n_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (user_ids, item_ids, labels) in enumerate(train_loader):\n",
        "        user_ids, item_ids, labels = (\n",
        "            user_ids.to(device),\n",
        "            item_ids.to(device),\n",
        "            labels.to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(user_ids, item_ids, device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # print train loss per every epoch\n",
        "    print(\"[Epoch {}]\".format(epoch + 1))\n",
        "    print(\"train_loss: \".format(epoch + 1), running_loss / len(train_loader))\n",
        "    loss_list.append(running_loss / len(train_loader))\n",
        "\n",
        "    # evaluate per every epoch\n",
        "    with torch.no_grad():\n",
        "        test_loss = 0\n",
        "        total_roc = 0\n",
        "        total_f1 = 0\n",
        "        for user_ids, item_ids, labels in test_loader:\n",
        "            user_ids, item_ids, labels = (\n",
        "                user_ids.to(device),\n",
        "                item_ids.to(device),\n",
        "                labels.to(device),\n",
        "            )\n",
        "            outputs = net(user_ids, item_ids, device)\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "            outputs = outputs.cpu().detach().numpy()\n",
        "            labels = labels.cpu().detach().numpy()\n",
        "            total_roc += roc_auc_score(labels, outputs)\n",
        "            outputs = np.where(outputs >= 0.5, 1, 0)\n",
        "            total_f1 += f1_score(labels, outputs)\n",
        "\n",
        "        print(\"test_loss: \".format(epoch + 1), test_loss / len(test_loader))\n",
        "        print(\"test_auc: \".format(epoch + 1), total_roc / len(test_loader))\n",
        "        print(\"test_f1: \".format(epoch + 1), total_f1 / len(test_loader))\n",
        "        print(\"--------------------------------\")\n",
        "        test_loss_list.append(test_loss / len(test_loader))\n",
        "        auc_score_list.append(total_roc / len(test_loader))\n",
        "        f1_score_list.append(total_f1 / len(test_loader))\n",
        "\n",
        "end_train = time.time()\n",
        "print(\"end_train:\", end_train)\n",
        "print(\"end_train - start_train:\", end_train - start_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "t8aPZCclm5wQ",
        "outputId": "3cfc95e6-d5a2-4918-8005-2cd9413abdd9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x288 with 3 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4))\n",
        "ax1.plot(loss_list)\n",
        "ax1.plot(test_loss_list)\n",
        "ax1.set_title(\"Loss\")\n",
        "ax2.plot(auc_score_list)\n",
        "ax2.set_title(\"AUC\")\n",
        "ax3.plot(f1_score_list)\n",
        "ax3.set_title(\"F1\")\n",
        "\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "KaJEag7gAs6d",
        "uS_vIFmTfhoR"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.13 ('kgcn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ad2f5f10d15a963e22c3bfe1d52a2dc2db7b5b0d344d326399ed0b0acae22bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
