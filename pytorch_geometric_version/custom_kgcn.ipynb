{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6qvp048fi06",
        "outputId": "c4afcff2-5ee7-414c-c43e-f2eb362f3a76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\anaconda3\\envs\\kgcn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.12.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ[\"TORCH\"] = torch.__version__\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoWDa5gHfiyP",
        "outputId": "863a23a4-f40c-4435-f2be-04982a6ebf7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wed Nov 16 21:34:51 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 497.29       Driver Version: 497.29       CUDA Version: 11.5     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   46C    P8     1W /  N/A |    134MiB /  4096MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RgIpZJnZfqy0"
      },
      "outputs": [],
      "source": [
        "# import required modules\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import copy\n",
        "import argparse\n",
        "from sklearn.metrics import roc_auc_score, f1_score\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim, Tensor\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch_sparse import SparseTensor, matmul\n",
        "\n",
        "from torch_geometric.utils import structured_negative_sampling\n",
        "from torch_geometric.data import download_url, extract_zip\n",
        "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.typing import Adj\n",
        "from torch_geometric.utils import structured_negative_sampling, subgraph, k_hop_subgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "rL-7y7SS64lb"
      },
      "outputs": [],
      "source": [
        "data_path = \"./data/\"\n",
        "# data_path = '/content/drive/MyDrive/AI_Naver_PTIT/KGCN/torch/data/'\n",
        "\n",
        "\n",
        "class DataLoader:\n",
        "    \"\"\"\n",
        "    Data Loader class which makes dataset for training / knowledge graph dictionary\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data):\n",
        "        self.cfg = {\n",
        "            \"movie\": {\n",
        "                \"item2id_path\": data_path + \"movie/item_index2entity_id.txt\",\n",
        "                \"kg_path\": data_path + \"movie/kg.txt\",\n",
        "                \"rating_path\": data_path + \"movie/ratings.csv\",\n",
        "                \"rating_sep\": \",\",\n",
        "                \"threshold\": 4.0,\n",
        "            },\n",
        "            \"music\": {\n",
        "                \"item2id_path\": data_path + \"music/item_index2entity_id.txt\",\n",
        "                \"kg_path\": data_path + \"music/kg.txt\",\n",
        "                \"rating_path\": data_path + \"music/user_artists.dat\",\n",
        "                \"rating_sep\": \"\\t\",\n",
        "                \"threshold\": 0.0,\n",
        "            },\n",
        "            'kkbox': {\n",
        "                'item2id_path': data_path + \"KKBOX_data/item_index2entity_id.txt\",\n",
        "                'kg_path': data_path + \"KKBOX_data/kg.txt\",\n",
        "                'rating_path': data_path + \"KKBOX_data/user_item.dat\",\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 0.0\n",
        "            },\n",
        "            'ml100k': {\n",
        "                'item2id_path': data_path + \"ML100K/item_index2entity_id.txt\",\n",
        "                'kg_path': data_path + \"ML100K/kg.txt\",\n",
        "                'rating_path': data_path + \"ML100K/user_item.dat\",\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 0.0\n",
        "            },\n",
        "            'bookcrossing': {\n",
        "                'item2id_path': data_path + 'BookCrossing/item_index2entity_id.txt',\n",
        "                'kg_path': data_path + 'BookCrossing/kg.txt',\n",
        "                'rating_path': data_path + 'BookCrossing/user_item.dat',\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 0.0\n",
        "            },\n",
        "            'ml1m': {\n",
        "                'item2id_path': data_path + 'ML1M/item_index2entity_id.txt',\n",
        "                'kg_path': data_path + 'ML1M/kg.txt',\n",
        "                'rating_path': data_path + 'ML1M/user_item.dat',\n",
        "                'rating_sep': '\\t',\n",
        "                'threshold': 4.0\n",
        "            }\n",
        "        }\n",
        "        self.data = data\n",
        "\n",
        "        df_item2id = pd.read_csv(\n",
        "            self.cfg[data][\"item2id_path\"], sep=\"\\t\", header=None, names=[\"item\", \"id\"]\n",
        "        )\n",
        "        df_kg = pd.read_csv(\n",
        "            self.cfg[data][\"kg_path\"],\n",
        "            sep=\"\\t\",\n",
        "            header=None,\n",
        "            names=[\"head\", \"relation\", \"tail\"],\n",
        "        )\n",
        "        df_rating = pd.read_csv(\n",
        "            self.cfg[data][\"rating_path\"],\n",
        "            sep=self.cfg[data][\"rating_sep\"],\n",
        "            names=[\"userID\", \"itemID\", \"rating\"],\n",
        "            skiprows=1,\n",
        "        )\n",
        "\n",
        "        # df_rating['itemID'] and df_item2id['item'] both represents old entity ID\n",
        "        df_rating = df_rating[df_rating[\"itemID\"].isin(df_item2id[\"item\"])]\n",
        "        df_rating.reset_index(inplace=True, drop=True)\n",
        "\n",
        "        self.df_item2id = df_item2id\n",
        "        self.df_kg = df_kg\n",
        "        self.df_rating = df_rating\n",
        "\n",
        "        self.user_encoder = LabelEncoder()\n",
        "        self.entity_encoder = LabelEncoder()\n",
        "        self.relation_encoder = LabelEncoder()\n",
        "\n",
        "        self._encoding()\n",
        "\n",
        "    def _encoding(self):\n",
        "        \"\"\"\n",
        "        Fit each label encoder and encode knowledge graph\n",
        "        \"\"\"\n",
        "        self.user_encoder.fit(self.df_rating[\"userID\"])\n",
        "        # df_item2id['id'] and df_kg[['head', 'tail']] represents new entity ID\n",
        "        self.entity_encoder.fit(\n",
        "            pd.concat([self.df_item2id[\"id\"], self.df_kg[\"head\"], self.df_kg[\"tail\"]])\n",
        "        )\n",
        "        self.relation_encoder.fit(self.df_kg[\"relation\"])\n",
        "\n",
        "        # encode df_kg\n",
        "        self.df_kg[\"head\"] = self.entity_encoder.transform(self.df_kg[\"head\"])\n",
        "        self.df_kg[\"tail\"] = self.entity_encoder.transform(self.df_kg[\"tail\"])\n",
        "        self.df_kg[\"relation\"] = self.relation_encoder.transform(self.df_kg[\"relation\"])\n",
        "\n",
        "    def _build_dataset(self):\n",
        "        \"\"\"\n",
        "        Build dataset for training (rating data)\n",
        "        It contains negative sampling process\n",
        "        \"\"\"\n",
        "        print(\"Build dataset dataframe ...\", end=\" \")\n",
        "        # df_rating update\n",
        "        df_dataset = pd.DataFrame()\n",
        "        df_dataset[\"userID\"] = self.user_encoder.transform(self.df_rating[\"userID\"])\n",
        "\n",
        "        # update to new id\n",
        "        item2id_dict = dict(zip(self.df_item2id[\"item\"], self.df_item2id[\"id\"]))\n",
        "        self.df_rating[\"itemID\"] = self.df_rating[\"itemID\"].apply(\n",
        "            lambda x: item2id_dict[x]\n",
        "        )\n",
        "        df_dataset[\"itemID\"] = self.entity_encoder.transform(self.df_rating[\"itemID\"])\n",
        "        df_dataset[\"label\"] = self.df_rating[\"rating\"].apply(\n",
        "            lambda x: 0 if x < self.cfg[self.data][\"threshold\"] else 1\n",
        "        )\n",
        "\n",
        "        # negative sampling\n",
        "        df_dataset = df_dataset[df_dataset[\"label\"] == 1]\n",
        "        # df_dataset requires columns to have new entity ID\n",
        "        full_item_set = set(range(len(self.entity_encoder.classes_)))\n",
        "        user_list = []\n",
        "        item_list = []\n",
        "        label_list = []\n",
        "        for user, group in df_dataset.groupby([\"userID\"]):\n",
        "            item_set = set(group[\"itemID\"])\n",
        "            negative_set = full_item_set - item_set\n",
        "            negative_sampled = random.sample(negative_set, len(item_set))\n",
        "            user_list.extend([user] * len(negative_sampled))\n",
        "            item_list.extend(negative_sampled)\n",
        "            label_list.extend([0] * len(negative_sampled))\n",
        "        negative = pd.DataFrame(\n",
        "            {\"userID\": user_list, \"itemID\": item_list, \"label\": label_list}\n",
        "        )\n",
        "        df_dataset = pd.concat([df_dataset, negative])\n",
        "\n",
        "        df_dataset = df_dataset.sample(frac=1, replace=False, random_state=999)\n",
        "        df_dataset.reset_index(inplace=True, drop=True)\n",
        "        print(\"Done\")\n",
        "        return df_dataset\n",
        "\n",
        "    def _construct_kg(self):\n",
        "        \"\"\"\n",
        "        Construct knowledge graph\n",
        "        Knowledge graph is dictionary form\n",
        "        'head': [(relation, tail), ...]\n",
        "        \"\"\"\n",
        "        print(\"Construct knowledge graph ...\", end=\" \")\n",
        "        kg = dict()\n",
        "        for i in range(len(self.df_kg)):\n",
        "            head = self.df_kg.iloc[i][\"head\"]\n",
        "            relation = self.df_kg.iloc[i][\"relation\"]\n",
        "            tail = self.df_kg.iloc[i][\"tail\"]\n",
        "            if head in kg:\n",
        "                kg[head].append((relation, tail))\n",
        "            else:\n",
        "                kg[head] = [(relation, tail)]\n",
        "            if tail in kg:\n",
        "                kg[tail].append((relation, head))\n",
        "            else:\n",
        "                kg[tail] = [(relation, head)]\n",
        "        print(\"Done\")\n",
        "        return kg\n",
        "\n",
        "    def load_dataset(self):\n",
        "        return self._build_dataset()\n",
        "\n",
        "    def load_kg(self):\n",
        "        return self._construct_kg()\n",
        "\n",
        "    def get_encoders(self):\n",
        "        return (self.user_encoder, self.entity_encoder, self.relation_encoder)\n",
        "\n",
        "    def get_num(self):\n",
        "        return (\n",
        "            len(self.user_encoder.classes_),\n",
        "            len(self.entity_encoder.classes_),\n",
        "            len(self.relation_encoder.classes_),\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KOc-sAwa64lc"
      },
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='music', help='which dataset to use')\n",
        "# parser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=25, help='the number of epochs')\n",
        "# parser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\n",
        "# parser.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\n",
        "# parser.add_argument('--batch_size', type=int, default=32, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UegvanGDbedf"
      },
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument(\"--dataset\", type=str, default=\"movie\", help=\"which dataset to use\")\n",
        "# parser.add_argument(\n",
        "#     \"--aggregator\", type=str, default=\"neighbor\", help=\"which aggregator to use\"\n",
        "# )\n",
        "# parser.add_argument(\"--n_epochs\", type=int, default=2, help=\"the number of epochs\")\n",
        "# parser.add_argument(\n",
        "#     \"--neighbor_sample_size\",\n",
        "#     type=int,\n",
        "#     default=4,\n",
        "#     help=\"the number of neighbors to be sampled\",\n",
        "# )\n",
        "# parser.add_argument(\n",
        "#     \"--dim\", type=int, default=32, help=\"dimension of user and entity embeddings\"\n",
        "# )\n",
        "# parser.add_argument(\n",
        "#     \"--n_iter\",\n",
        "#     type=int,\n",
        "#     default=2,\n",
        "#     help=\"number of iterations when computing entity representation\",\n",
        "# )\n",
        "# parser.add_argument(\"--batch_size\", type=int, default=65536, help=\"batch size\")\n",
        "# parser.add_argument(\n",
        "#     \"--l2_weight\", type=float, default=1e-7, help=\"weight of l2 regularization\"\n",
        "# )\n",
        "# parser.add_argument(\"--lr\", type=float, default=2e-2, help=\"learning rate\")\n",
        "# parser.add_argument(\"--ratio\", type=float, default=0.6, help=\"size of training dataset\")\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='kkbox', help='which dataset to use')\n",
        "# parser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=100, help='the number of epochs')\n",
        "# parser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\n",
        "# parser.add_argument('--dim', type=int, default=32, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\n",
        "# parser.add_argument('--batch_size', type=int, default=32768, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-7, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=2e-2, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "parser.add_argument('--dataset', type=str, default='ml100k', help='which dataset to use')\n",
        "parser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\n",
        "parser.add_argument('--n_epochs', type=int, default=100, help='the number of epochs')\n",
        "parser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\n",
        "parser.add_argument('--dim', type=int, default=16, help='dimension of user and entity embeddings')\n",
        "parser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\n",
        "parser.add_argument('--batch_size', type=int, default=16, help='batch size')\n",
        "parser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\n",
        "parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='bookcrossing', help='which dataset to use')\n",
        "# parser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=100, help='the number of epochs')\n",
        "# parser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\n",
        "# parser.add_argument('--dim', type=int, default=32, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\n",
        "# parser.add_argument('--batch_size', type=int, default=128, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-4, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=5e-4, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parser = argparse.ArgumentParser()\n",
        "\n",
        "# parser.add_argument('--dataset', type=str, default='ml1m', help='which dataset to use')\n",
        "# parser.add_argument('--aggregator', type=str, default='sum', help='which aggregator to use')\n",
        "# parser.add_argument('--n_epochs', type=int, default=100, help='the number of epochs')\n",
        "# parser.add_argument('--neighbor_sample_size', type=int, default=8, help='the number of neighbors to be sampled')\n",
        "# parser.add_argument('--dim', type=int, default=32, help='dimension of user and entity embeddings')\n",
        "# parser.add_argument('--n_iter', type=int, default=1, help='number of iterations when computing entity representation')\n",
        "# parser.add_argument('--batch_size', type=int, default=2048, help='batch size')\n",
        "# parser.add_argument('--l2_weight', type=float, default=1e-7, help='weight of l2 regularization')\n",
        "# parser.add_argument('--lr', type=float, default=2e-2, help='learning rate')\n",
        "# parser.add_argument('--ratio', type=float, default=0.6, help='size of training dataset')\n",
        "\n",
        "# args = parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDu2qqog64ld",
        "outputId": "d6c72b7b-7d69-4c63-d318-e268a35cd237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Construct knowledge graph ... Done\n",
            "Build dataset dataframe ... Done\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userID</th>\n",
              "      <th>itemID</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>124</td>\n",
              "      <td>3321</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>681</td>\n",
              "      <td>4464</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>346</td>\n",
              "      <td>5188</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>404</td>\n",
              "      <td>662</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>270</td>\n",
              "      <td>646</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199943</th>\n",
              "      <td>192</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199944</th>\n",
              "      <td>384</td>\n",
              "      <td>6021</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199945</th>\n",
              "      <td>337</td>\n",
              "      <td>1995</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199946</th>\n",
              "      <td>534</td>\n",
              "      <td>204</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199947</th>\n",
              "      <td>48</td>\n",
              "      <td>79</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>199948 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        userID  itemID  label\n",
              "0          124    3321      0\n",
              "1          681    4464      0\n",
              "2          346    5188      0\n",
              "3          404     662      1\n",
              "4          270     646      1\n",
              "...        ...     ...    ...\n",
              "199943     192       1      1\n",
              "199944     384    6021      0\n",
              "199945     337    1995      0\n",
              "199946     534     204      1\n",
              "199947      48      79      1\n",
              "\n",
              "[199948 rows x 3 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build dataset and knowledge graph\n",
        "data_loader = DataLoader(args.dataset)\n",
        "kg = data_loader.load_kg()\n",
        "df_dataset = data_loader.load_dataset()\n",
        "df_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "AfQI1bJT64ld"
      },
      "outputs": [],
      "source": [
        "# Dataset class\n",
        "class KGCNDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user_id = np.array(self.df.iloc[idx][\"userID\"])\n",
        "        item_id = np.array(self.df.iloc[idx][\"itemID\"])\n",
        "        label = np.array(self.df.iloc[idx][\"label\"], dtype=np.float32)\n",
        "        return user_id, item_id, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wgV6Yq2i64ld"
      },
      "outputs": [],
      "source": [
        "# train test split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    df_dataset,\n",
        "    df_dataset[\"label\"],\n",
        "    test_size=1 - args.ratio,\n",
        "    shuffle=False,\n",
        "    random_state=999,\n",
        ")\n",
        "x_val, x_test, y_val, y_test = train_test_split(\n",
        "    x_test, y_test, test_size=0.5, shuffle=False, random_state=999\n",
        ")\n",
        "train_dataset = KGCNDataset(x_train)\n",
        "val_dataset = KGCNDataset(x_val)\n",
        "test_dataset = KGCNDataset(x_test)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args.batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_dataset.__len__())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z63rfq-Gipwp"
      },
      "source": [
        "## model v1: loop in batch + 1-hop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WyZBfI-yB7Rx"
      },
      "outputs": [],
      "source": [
        "class KGCN_geometric_v1(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(KGCN_geometric_v1, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.n_iter = args.n_iter\n",
        "        self.batch_size = args.batch_size\n",
        "        self.dim = args.dim\n",
        "        self.n_neighbor = args.neighbor_sample_size\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self.aggregator = args.aggregator\n",
        "\n",
        "        self._gen_adj()\n",
        "\n",
        "        self.usr = torch.nn.Embedding(num_user, args.dim)\n",
        "        self.ent = torch.nn.Embedding(num_ent, args.dim)\n",
        "        self.rel = torch.nn.Embedding(num_rel, args.dim)\n",
        "\n",
        "        if self.aggregator == \"concat\":\n",
        "            self.weights_update = torch.nn.Linear(2 * args.dim, args.dim, bias=True)\n",
        "        else:\n",
        "            self.weights_update = torch.nn.Linear(args.dim, args.dim, bias=True)\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "        self.adj_ent = torch.empty(self.num_ent, self.n_neighbor, dtype=torch.long)\n",
        "        self.adj_rel = torch.empty(self.num_ent, self.n_neighbor, dtype=torch.long)\n",
        "\n",
        "        indices = [[], []]\n",
        "        values = []\n",
        "\n",
        "        test_indices = []\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.n_neighbor:\n",
        "                neighbors = random.sample(self.kg[e], self.n_neighbor)\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.n_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors = random.choices(self.kg[e], k=self.n_neighbor)\n",
        "                neighbors_to_sparse_coo_tensor = self.kg[e]\n",
        "\n",
        "            self.adj_ent[e] = torch.LongTensor([ent for _, ent in neighbors])\n",
        "            self.adj_rel[e] = torch.LongTensor([rel for rel, _ in neighbors])\n",
        "\n",
        "            for rel, ent in neighbors_to_sparse_coo_tensor:\n",
        "                indices[0].append(ent)\n",
        "                indices[1].append(e)\n",
        "                values.append(rel)\n",
        "\n",
        "        self.edge_index = torch.tensor(indices)\n",
        "        self.edge_attr = torch.tensor(values)\n",
        "\n",
        "    def forward(self, user_indices, item_indices, device):\n",
        "\n",
        "        list_batch_score = torch.tensor([]).to(device)\n",
        "\n",
        "        for i, u in zip(\n",
        "            item_indices, user_indices\n",
        "        ):  # edge_index_subset[1] ~ target node\n",
        "            i_ = i.item()\n",
        "            u_ = u.item()\n",
        "\n",
        "            # get subset of target node i from\n",
        "            (\n",
        "                subset_i,\n",
        "                edge_index_subset_i,\n",
        "                mapping_i,\n",
        "                edge_mask_subset_i,\n",
        "            ) = k_hop_subgraph(i_, 1, self.edge_index)\n",
        "            edge_index_subset_i, edge_attr_subset_i = subgraph(\n",
        "                subset_i, self.edge_index, self.edge_attr\n",
        "            )\n",
        "\n",
        "            # reshape test [-1, 2]\n",
        "            edge_index_subset_i = edge_index_subset_i.t().reshape(-1, 2)\n",
        "\n",
        "            # get only row that have i in second column and get mask\n",
        "            edge_mask_subset_i = edge_index_subset_i[:, 1] == i_\n",
        "            edge_attr_subset_i = edge_attr_subset_i[edge_mask_subset_i]\n",
        "            edge_index_subset_i = edge_index_subset_i[edge_mask_subset_i]\n",
        "\n",
        "            # reshape test [2, -1]\n",
        "            edge_index_subset_i = edge_index_subset_i.t().reshape(2, -1)\n",
        "            edge_index_subset_i = edge_index_subset_i.to(device)\n",
        "            edge_attr_subset_i = edge_attr_subset_i.to(device)\n",
        "\n",
        "            # get user emb by with index u\n",
        "            user_embedding = self.usr(u)\n",
        "\n",
        "            relation_vectors = self.rel(edge_attr_subset_i)\n",
        "\n",
        "            # get item emb is item_emb\n",
        "            user_relation_score = (user_embedding * relation_vectors).sum(dim=-1)\n",
        "\n",
        "            user_relation_score_normalized = F.softmax(user_relation_score, dim=-1)\n",
        "\n",
        "            item_emb = self.propagate(\n",
        "                edge_index_subset_i,\n",
        "                x=self.ent.weight,\n",
        "                user_relation_score_normalized=user_relation_score_normalized,\n",
        "                id_item_src=i_,\n",
        "            )\n",
        "\n",
        "            score = (item_emb * user_embedding).sum(dim=-1)\n",
        "\n",
        "            list_batch_score = torch.cat((list_batch_score, score.unsqueeze(-1)))\n",
        "\n",
        "        return torch.sigmoid(list_batch_score)\n",
        "\n",
        "    def message(self, x_j, user_relation_score_normalized) -> Tensor:\n",
        "        user_relation_score_normalized = user_relation_score_normalized.unsqueeze(\n",
        "            dim=-1\n",
        "        )\n",
        "        neighbor_vectors = x_j\n",
        "        neighbors_aggregated = user_relation_score_normalized * neighbor_vectors\n",
        "        return neighbors_aggregated\n",
        "\n",
        "    def update(self, aggr_out, x_i, id_item_src):\n",
        "        self_vectors = x_i[0]\n",
        "        neighbors_agg = aggr_out[id_item_src]\n",
        "\n",
        "        if self.aggregator == \"sum\":\n",
        "            output = self_vectors + neighbors_agg\n",
        "        elif self.aggregator == \"concat\":\n",
        "            output = torch.cat((self_vectors, neighbors_agg))\n",
        "        else:\n",
        "            output = neighbors_agg\n",
        "        output = self.weights_update(output)\n",
        "        return torch.tanh(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AJ6wBcRiwO9"
      },
      "source": [
        "## model v2: parallel in batch + 1-hop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvU-qA4slz0Q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "class KGCN_geometric_v2(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(KGCN_geometric_v2, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.n_iter = args.n_iter\n",
        "        self.batch_size = args.batch_size\n",
        "        self.dim = args.dim\n",
        "        self.n_neighbor = args.neighbor_sample_size\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self.aggregator = args.aggregator\n",
        "\n",
        "        self._gen_adj()\n",
        "\n",
        "        self.usr = torch.nn.Embedding(num_user, args.dim)\n",
        "        self.ent = torch.nn.Embedding(num_ent, args.dim)\n",
        "        self.rel = torch.nn.Embedding(num_rel, args.dim)\n",
        "\n",
        "        if self.aggregator == \"concat\":\n",
        "            self.weights_update = torch.nn.Linear(2 * args.dim, args.dim, bias=True)\n",
        "        else:\n",
        "            self.weights_update = torch.nn.Linear(args.dim, args.dim, bias=True)\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "\n",
        "        indices = [[], []]\n",
        "        values = []\n",
        "\n",
        "        test_indices = []\n",
        "\n",
        "        self.list_id_neighbor = np.full((self.num_ent, self.n_neighbor), -1)\n",
        "        self.list_id_edge = np.full((self.num_ent, self.n_neighbor), -1)\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.n_neighbor:\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.n_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors_to_sparse_coo_tensor = random.choices(\n",
        "                    self.kg[e], k=self.n_neighbor\n",
        "                )\n",
        "            self.list_id_neighbor[e] = [\n",
        "                ent for _, ent in neighbors_to_sparse_coo_tensor\n",
        "            ]\n",
        "            self.list_id_edge[e] = [rel for rel, _ in neighbors_to_sparse_coo_tensor]\n",
        "            for rel, ent in neighbors_to_sparse_coo_tensor:\n",
        "                indices[0].append(ent)\n",
        "                indices[1].append(e)\n",
        "                values.append(rel)\n",
        "\n",
        "        self.edge_index = torch.tensor(indices)\n",
        "        self.edge_attr = torch.tensor(values)\n",
        "\n",
        "    def forward(self, user_indices, item_indices, device):\n",
        "\n",
        "        list_node_id_1_hop_item = torch.tensor(\n",
        "            np.array(\n",
        "                [\n",
        "                    self.list_id_neighbor[item_indices].flatten(),\n",
        "                    np.array(np.repeat(item_indices, self.n_neighbor)),\n",
        "                ],\n",
        "                dtype=np.int64,\n",
        "            )\n",
        "        ).to(device)\n",
        "        list_edge_attr_id_1_hop_item = torch.tensor(self.list_id_edge[item_indices]).to(\n",
        "            device\n",
        "        )\n",
        "\n",
        "        user_embeddings = self.usr(user_indices)\n",
        "\n",
        "        relation_vectors = self.rel(list_edge_attr_id_1_hop_item)\n",
        "\n",
        "        user_relation_scores = (\n",
        "            user_embeddings.view((-1, 1, self.dim)) * relation_vectors\n",
        "        ).sum(dim=-1)\n",
        "\n",
        "        user_relation_scores_normalized = F.softmax(user_relation_scores, dim=-1)\n",
        "\n",
        "        item_embs = self.propagate(\n",
        "            list_node_id_1_hop_item,\n",
        "            x=self.ent.weight,\n",
        "            user_relation_scores_normalized=user_relation_scores_normalized,\n",
        "            item_indices=item_indices,\n",
        "        )\n",
        "\n",
        "        scores = (item_embs * user_embeddings).sum(dim=-1)\n",
        "\n",
        "        return torch.sigmoid(scores)\n",
        "\n",
        "    def message(self, x_j, user_relation_scores_normalized, item_indices) -> Tensor:\n",
        "        user_relation_scores_normalized = torch.flatten(\n",
        "            user_relation_scores_normalized\n",
        "        ).view(-1, 1)\n",
        "        neighbor_vectors = x_j\n",
        "        neighbors_aggregated = user_relation_scores_normalized * neighbor_vectors\n",
        "        return neighbors_aggregated\n",
        "\n",
        "    def update(self, aggr_out, x_i, item_indices):\n",
        "        self_vectors = x_i[:: self.n_neighbor]\n",
        "        neighbors_agg = aggr_out[item_indices]\n",
        "        if self.aggregator == \"sum\":\n",
        "            output = self_vectors + neighbors_agg\n",
        "        elif self.aggregator == \"concat\":\n",
        "            output = torch.cat((self_vectors, neighbors_agg))\n",
        "        else:\n",
        "            output = neighbors_agg\n",
        "        output = self.weights_update(output)\n",
        "        return torch.tanh(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3WDhFd8kxku"
      },
      "source": [
        "## model v3: parallel in batch + k-hop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "70rp7-Q9k-fR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "class KGCN_geometric_v3(MessagePassing):\n",
        "    def __init__(self, num_user, num_ent, num_rel, kg, args, device):\n",
        "        super(KGCN_geometric_v3, self).__init__(aggr=\"add\")\n",
        "        self.num_user = num_user\n",
        "        self.num_ent = num_ent\n",
        "        self.num_rel = num_rel\n",
        "        self.n_iter = args.n_iter\n",
        "        self.batch_size = args.batch_size\n",
        "        self.dim = args.dim\n",
        "        self.n_neighbor = args.neighbor_sample_size\n",
        "        self.kg = kg\n",
        "        self.device = device\n",
        "        self.aggregator = args.aggregator\n",
        "\n",
        "        self._gen_adj()\n",
        "\n",
        "        self.usr = torch.nn.Embedding(num_user, args.dim)\n",
        "        self.ent = torch.nn.Embedding(num_ent, args.dim)\n",
        "        self.rel = torch.nn.Embedding(num_rel, args.dim)\n",
        "\n",
        "        if self.aggregator == \"concat\":\n",
        "            self.weights_update = torch.nn.Linear(2 * args.dim, args.dim, bias=True)\n",
        "        else:\n",
        "            self.weights_update = torch.nn.Linear(args.dim, args.dim, bias=True)\n",
        "\n",
        "    def _gen_adj(self):\n",
        "        \"\"\"\n",
        "        Generate adjacency matrix for entities and relations\n",
        "        Only cares about fixed number of samples\n",
        "        \"\"\"\n",
        "\n",
        "        indices = [[], []]\n",
        "        values = []\n",
        "\n",
        "        test_indices = []\n",
        "\n",
        "        self.list_id_neighbor = np.full((self.num_ent, self.n_neighbor), -1)\n",
        "        self.list_id_edge = np.full((self.num_ent, self.n_neighbor), -1)\n",
        "\n",
        "        for e in self.kg:\n",
        "            if len(self.kg[e]) >= self.n_neighbor:\n",
        "                neighbors_to_sparse_coo_tensor = random.sample(\n",
        "                    self.kg[e], self.n_neighbor\n",
        "                )\n",
        "            else:\n",
        "                neighbors_to_sparse_coo_tensor = random.choices(\n",
        "                    self.kg[e], k=self.n_neighbor\n",
        "                )\n",
        "            self.list_id_neighbor[e] = [\n",
        "                ent for _, ent in neighbors_to_sparse_coo_tensor\n",
        "            ]\n",
        "            self.list_id_edge[e] = [rel for rel, _ in neighbors_to_sparse_coo_tensor]\n",
        "            for rel, ent in neighbors_to_sparse_coo_tensor:\n",
        "                indices[0].append(ent)\n",
        "                indices[1].append(e)\n",
        "                values.append(rel)\n",
        "\n",
        "        self.edge_index = torch.tensor(indices)\n",
        "        self.edge_attr = torch.tensor(values)\n",
        "\n",
        "    def forward(self, user_indices_origin, item_indices_origin, device):\n",
        "\n",
        "        list_k_hop_user = [user_indices_origin]\n",
        "        list_k_hop_item = [item_indices_origin]\n",
        "\n",
        "        list_ent_weight = [self.ent.weight]\n",
        "\n",
        "        for i in range(self.n_iter - 1):\n",
        "\n",
        "            unique_id_neighbor, unique_indices = np.unique(\n",
        "                self.list_id_neighbor[list_k_hop_item[0].cpu()], return_index=True\n",
        "            )\n",
        "            list_k_hop_user.insert(\n",
        "                0,\n",
        "                np.repeat(list_k_hop_user[0].cpu(), self.n_neighbor)[unique_indices]\n",
        "                .clone()\n",
        "                .detach(),\n",
        "            )\n",
        "            list_k_hop_item.insert(0, torch.tensor(unique_id_neighbor))\n",
        "\n",
        "        current_hop = 0\n",
        "\n",
        "        for user_indices, item_indices in zip(list_k_hop_user, list_k_hop_item):\n",
        "            user_indices = user_indices.to(device)\n",
        "            # user_indices = torch.tensor(user_indices.clone().detach()).to(device)\n",
        "            # user_indices = user_indices.clone().detach()\n",
        "\n",
        "            if current_hop == self.n_iter - 1:\n",
        "                act = torch.tanh\n",
        "            else:\n",
        "                act = torch.sigmoid\n",
        "            current_hop += 1\n",
        "            list_node_id_1_hop_item = torch.tensor(\n",
        "                np.array(\n",
        "                    [\n",
        "                        self.list_id_neighbor[item_indices.cpu()].flatten(),\n",
        "                        np.array(np.repeat(item_indices.cpu(), self.n_neighbor)),\n",
        "                    ],\n",
        "                    dtype=np.int64,\n",
        "                )\n",
        "            ).to(device)\n",
        "            list_edge_attr_id_1_hop_item = torch.tensor(\n",
        "                self.list_id_edge[item_indices.cpu()]\n",
        "            ).to(device)\n",
        "\n",
        "            user_embeddings = self.usr(user_indices)\n",
        "            relation_vectors = self.rel(list_edge_attr_id_1_hop_item)\n",
        "\n",
        "            user_relation_scores = (\n",
        "                user_embeddings.view((-1, 1, self.dim)) * relation_vectors\n",
        "            ).sum(dim=-1)\n",
        "            user_relation_scores_normalized = F.softmax(user_relation_scores, dim=-1)\n",
        "\n",
        "            item_embs = self.propagate(\n",
        "                list_node_id_1_hop_item,\n",
        "                x=list_ent_weight[-1],\n",
        "                user_relation_scores_normalized=user_relation_scores_normalized,\n",
        "                item_indices=item_indices,\n",
        "                act=act,\n",
        "            )\n",
        "            tmp = list_ent_weight[-1].clone()\n",
        "            tmp[item_indices] = item_embs\n",
        "            list_ent_weight.append(tmp)\n",
        "\n",
        "        scores = (item_embs * user_embeddings).sum(dim=-1)\n",
        "\n",
        "        return torch.sigmoid(scores)\n",
        "\n",
        "    def message(\n",
        "        self, x_j, user_relation_scores_normalized, item_indices, act\n",
        "    ) -> Tensor:\n",
        "        user_relation_scores_normalized = torch.flatten(\n",
        "            user_relation_scores_normalized\n",
        "        ).view(-1, 1)\n",
        "        neighbor_vectors = x_j\n",
        "        neighbors_aggregated = user_relation_scores_normalized * neighbor_vectors\n",
        "        return neighbors_aggregated\n",
        "\n",
        "    def update(self, aggr_out, x_i, item_indices, act):\n",
        "        self_vectors = x_i[:: self.n_neighbor]\n",
        "        neighbors_agg = aggr_out[item_indices]\n",
        "        if self.aggregator == \"sum\":\n",
        "            output = self_vectors + neighbors_agg\n",
        "        elif self.aggregator == \"concat\":\n",
        "            output = torch.cat((self_vectors, neighbors_agg), 1)\n",
        "        else:\n",
        "            output = neighbors_agg\n",
        "        output = self.weights_update(output)\n",
        "        return act(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c47hw08Mix3c"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9azw7_BoGxmP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "device:  cuda\n"
          ]
        }
      ],
      "source": [
        "# prepare network, loss function, optimizer\n",
        "num_user, num_entity, num_relation = data_loader.get_num()\n",
        "user_encoder, entity_encoder, relation_encoder = data_loader.get_encoders()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = KGCN_geometric_v3(num_user, num_entity, num_relation, kg, args, device).to(device)\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = optim.Adam(net.parameters(), lr=args.lr, weight_decay=args.l2_weight)\n",
        "print(\"device: \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "name_version = \"KGCN_geometric\"\n",
        "patience = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start_train: 1668615895.3795166\n",
            "[Epoch 1]\n",
            "train_loss:  0.7530119030968162\n",
            "val_loss:  0.6268425005197525\n",
            "val_auc:  0.7318534294871865\n",
            "val_f1:  0.689697805879841\n",
            "--------------------------------\n",
            "Validation loss decreased (inf --> 0.626843).  Saving model ...\n",
            "[Epoch 2]\n",
            "train_loss:  0.5380868607320668\n",
            "val_loss:  0.4278646178603172\n",
            "val_auc:  0.8871415692640742\n",
            "val_f1:  0.8273852800493281\n",
            "--------------------------------\n",
            "Validation loss decreased (0.626843 --> 0.427865).  Saving model ...\n",
            "[Epoch 3]\n",
            "train_loss:  0.3162805689178322\n",
            "val_loss:  0.25619533848911524\n",
            "val_auc:  0.9569658036408044\n",
            "val_f1:  0.9063461733368382\n",
            "--------------------------------\n",
            "Validation loss decreased (0.427865 --> 0.256195).  Saving model ...\n",
            "[Epoch 4]\n",
            "train_loss:  0.23930880247207126\n",
            "val_loss:  0.23701155314296485\n",
            "val_auc:  0.9595681464368967\n",
            "val_f1:  0.9106198421638545\n",
            "--------------------------------\n",
            "Validation loss decreased (0.256195 --> 0.237012).  Saving model ...\n",
            "[Epoch 5]\n",
            "train_loss:  0.2295905004369001\n",
            "val_loss:  0.23289675936996937\n",
            "val_auc:  0.9602628815628809\n",
            "val_f1:  0.9125709455717468\n",
            "--------------------------------\n",
            "EarlyStopping counter: 1 out of 5\n",
            "[Epoch 6]\n",
            "train_loss:  0.22583195456236832\n",
            "val_loss:  0.2305524566680193\n",
            "val_auc:  0.9606960095460092\n",
            "val_f1:  0.9140188410702543\n",
            "--------------------------------\n",
            "Validation loss decreased (0.237012 --> 0.230552).  Saving model ...\n",
            "[Epoch 7]\n",
            "train_loss:  0.22332372102701614\n",
            "val_loss:  0.2289795190781355\n",
            "val_auc:  0.9610633817571314\n",
            "val_f1:  0.9152354307071975\n",
            "--------------------------------\n",
            "EarlyStopping counter: 1 out of 5\n",
            "[Epoch 8]\n",
            "train_loss:  0.22144074299218464\n",
            "val_loss:  0.2279044532224536\n",
            "val_auc:  0.9613166729104234\n",
            "val_f1:  0.9160837911732129\n",
            "--------------------------------\n",
            "EarlyStopping counter: 2 out of 5\n",
            "[Epoch 9]\n",
            "train_loss:  0.2199411037248587\n",
            "val_loss:  0.2270251227527857\n",
            "val_auc:  0.9614444932844939\n",
            "val_f1:  0.9164801846575047\n",
            "--------------------------------\n",
            "EarlyStopping counter: 3 out of 5\n",
            "[Epoch 10]\n",
            "train_loss:  0.21860879361723884\n",
            "val_loss:  0.226218111731112\n",
            "val_auc:  0.9617090011377512\n",
            "val_f1:  0.916858003496568\n",
            "--------------------------------\n",
            "EarlyStopping counter: 4 out of 5\n",
            "[Epoch 11]\n",
            "train_loss:  0.2173334582584318\n",
            "val_loss:  0.22543146220445634\n",
            "val_auc:  0.9620438553113559\n",
            "val_f1:  0.9170936911366676\n",
            "--------------------------------\n",
            "Validation loss decreased (0.230552 --> 0.225431).  Saving model ...\n",
            "[Epoch 12]\n",
            "train_loss:  0.21608897183159012\n",
            "val_loss:  0.22466298593878747\n",
            "val_auc:  0.962380486735488\n",
            "val_f1:  0.9172006011199108\n",
            "--------------------------------\n",
            "EarlyStopping counter: 1 out of 5\n",
            "[Epoch 13]\n",
            "train_loss:  0.21488729193429051\n",
            "val_loss:  0.22392404987812042\n",
            "val_auc:  0.9626847773060286\n",
            "val_f1:  0.9172299831149814\n",
            "--------------------------------\n",
            "EarlyStopping counter: 2 out of 5\n",
            "[Epoch 14]\n",
            "train_loss:  0.21374996564661297\n",
            "val_loss:  0.22322820984870195\n",
            "val_auc:  0.962975410977912\n",
            "val_f1:  0.9169815824313753\n",
            "--------------------------------\n",
            "EarlyStopping counter: 3 out of 5\n",
            "[Epoch 15]\n",
            "train_loss:  0.21269485107271527\n",
            "val_loss:  0.22258795588463545\n",
            "val_auc:  0.9630434265734275\n",
            "val_f1:  0.9168783011037384\n",
            "--------------------------------\n",
            "EarlyStopping counter: 4 out of 5\n",
            "[Epoch 16]\n",
            "train_loss:  0.21173187528897616\n",
            "val_loss:  0.22201038009375335\n",
            "val_auc:  0.9633681186868692\n",
            "val_f1:  0.9168572521359154\n",
            "--------------------------------\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Early stopping\n",
            "end_train: 1668617350.9158401\n",
            "end_train - start_train: 1455.5363235473633\n"
          ]
        }
      ],
      "source": [
        "from pytorchtools import EarlyStopping\n",
        "# add early stopping\n",
        "early_stopping = EarlyStopping(patience=patience, verbose=True, path=f'./checkpoint/{name_version}_{args.dataset}.pt', delta=0.005)\n",
        "\n",
        "# train\n",
        "loss_list = []\n",
        "val_loss_list = []\n",
        "auc_score_list = []\n",
        "f1_score_list = []\n",
        "\n",
        "import time\n",
        "\n",
        "start_train = time.time()\n",
        "print(\"start_train:\", start_train)\n",
        "\n",
        "\n",
        "for epoch in range(args.n_epochs):\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, (user_ids, item_ids, labels) in enumerate(train_loader):\n",
        "        user_ids, item_ids, labels = (\n",
        "            user_ids.to(device),\n",
        "            item_ids.to(device),\n",
        "            labels.to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(user_ids, item_ids, device)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # print train loss per every epoch\n",
        "    print(\"[Epoch {}]\".format(epoch + 1))\n",
        "    print(\"train_loss: \".format(epoch + 1), running_loss / len(train_loader))\n",
        "    loss_list.append(running_loss / len(train_loader))\n",
        "\n",
        "    # evaluate per every epoch\n",
        "    with torch.no_grad():\n",
        "        val_loss = 0\n",
        "        total_roc = 0\n",
        "        total_f1 = 0\n",
        "        for user_ids, item_ids, labels in val_loader:\n",
        "            user_ids, item_ids, labels = (\n",
        "                user_ids.to(device),\n",
        "                item_ids.to(device),\n",
        "                labels.to(device),\n",
        "            )\n",
        "            outputs = net(user_ids, item_ids, device)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "            outputs = outputs.cpu().detach().numpy()\n",
        "            labels = labels.cpu().detach().numpy()\n",
        "            total_roc += roc_auc_score(labels, outputs)\n",
        "            outputs = np.where(outputs >= 0.5, 1, 0)\n",
        "            total_f1 += f1_score(labels, outputs)\n",
        "\n",
        "        print(\"val_loss: \".format(epoch + 1), val_loss / len(val_loader))\n",
        "        print(\"val_auc: \".format(epoch + 1), total_roc / len(val_loader))\n",
        "        print(\"val_f1: \".format(epoch + 1), total_f1 / len(val_loader))\n",
        "        print(\"--------------------------------\")\n",
        "        val_loss_list.append(val_loss / len(val_loader))\n",
        "        auc_score_list.append(total_roc / len(val_loader))\n",
        "        f1_score_list.append(total_f1 / len(val_loader))\n",
        "\n",
        "    # early stopping\n",
        "    early_stopping(val_loss / len(val_loader), net)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "end_train = time.time()\n",
        "print(\"end_train:\", end_train)\n",
        "print(\"end_train - start_train:\", end_train - start_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4oUpfjYb0Mwc",
        "outputId": "efca37f1-462c-4198-838e-413d6d53877d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(10, 4))\n",
        "ax1.plot(loss_list)\n",
        "ax1.plot(val_loss_list)\n",
        "ax1.set_title(\"Loss\")\n",
        "ax2.plot(auc_score_list)\n",
        "ax2.set_title(\"AUC\")\n",
        "ax3.plot(f1_score_list)\n",
        "ax3.set_title(\"F1\")\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outputs: [0.9889798  0.02696869 0.9879354  ... 0.9639119  0.9843089  0.9814761 ]\n",
            "labels: [1. 0. 1. ... 0. 1. 1.]\n",
            "test_auc:  0.8455148253440717\n",
            "test_f1:  0.8186439953859956\n"
          ]
        }
      ],
      "source": [
        "# load the last checkpoint with the best model\n",
        "net = KGCN_geometric_v3(num_user, num_entity, num_relation, kg, args, device).to(device)\n",
        "net.load_state_dict(torch.load(f'./checkpoint/{name_version}_{args.dataset}.pt'))\n",
        "\n",
        "# test\n",
        "with torch.no_grad():\n",
        "    total_roc = 0\n",
        "    total_f1 = 0\n",
        "    for user_ids, item_ids, labels in test_loader:\n",
        "        user_ids, item_ids, labels = (\n",
        "            user_ids.to(device),\n",
        "            item_ids.to(device),\n",
        "            labels.to(device),\n",
        "        )\n",
        "        outputs = net(user_ids, item_ids, device)\n",
        "        outputs = outputs.cpu().detach().numpy()\n",
        "        labels = labels.cpu().detach().numpy()\n",
        "        print(\"outputs:\", outputs)\n",
        "        print(\"labels:\", labels)\n",
        "        total_roc += roc_auc_score(labels, outputs)\n",
        "        outputs = np.where(outputs >= 0.5, 1, 0)\n",
        "        total_f1 += f1_score(labels, outputs)\n",
        "\n",
        "    print(\"test_auc: \", total_roc / len(test_loader))\n",
        "    print(\"test_f1: \", total_f1 / len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "z63rfq-Gipwp",
        "6AJ6wBcRiwO9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.15 ('kgcn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "8ad2f5f10d15a963e22c3bfe1d52a2dc2db7b5b0d344d326399ed0b0acae22bf"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
